{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING ALL THE REQUORED LIBRARIES\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver \n",
    "import numpy as np \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to web drivers \n",
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONNECTING TO THE WEBSITE \n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#THINGS TO SCRAP \n",
    "job-title, job-location, company_name, experience_required.---Data Analyst” Job position in “Bangalore” location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering job title in the search box \n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location in the search box \n",
    "search_location=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the button \n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to use for data storage \n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying url of page to scrap \n",
    "DAurl=\"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\"\n",
    "driver.get(DAurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"d9735ac8-4bfd-49f3-9c1c-cb93c043f86b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"742ba311-b8e9-4cbe-b913-707eea2de1aa\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"c854b110-b2b5-48ec-8de2-de59c2bfd25f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"459e8b69-3f2b-4e8b-8fbf-404d2f6c7ba0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"cfa13fea-333f-466c-82ce-8eb044be5c70\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"1b6c6e3f-7d1d-4624-83b4-fabe85a5d47b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"b96260be-5fa3-44ed-bce6-eb620a950773\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"367b40d1-a689-4205-b6eb-abb519b4f84a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"70eb5765-38fc-4198-96ad-6cfc05e5337e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"4c651b7c-51be-41b5-9415-f469e0e7f891\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"083450d5-f265-41d2-99b4-00619e3b88d8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"d3b6d6cd-c7d2-483e-9b50-692a2e673868\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"3f33a20c-fd47-4b34-a63a-12be896c7d39\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"0e45c560-d79c-4ba2-a99e-e2304b72220d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"b312791d-463d-4c59-a5a6-4297d13e6bdd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"a60ec395-f461-4e5c-844c-2129c1ff3c91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"ce9980c1-9343-46a5-8597-5a8890d686c0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"04f5d3b1-c2e7-47c1-8941-ac0da6debd42\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"73902226-6f90-4c1e-9440-0f69658859d1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"8c9f69f8-d7ad-485b-aed3-c3ac0d4389fd\")>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['SQL Data Analyst',\n",
       " 'Data Analyst - Marketing',\n",
       " 'Openings For Data Analyst',\n",
       " 'Associate Data Analyst',\n",
       " 'Business Data Analyst',\n",
       " 'Data Analyst / Business Analyst (Demand Planning)',\n",
       " 'Data Analyst',\n",
       " 'Lead Data Analyst / Data Engineer',\n",
       " 'Business Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - Monetisation & Promotion Platform (MPP)',\n",
       " 'Data Analyst - Monetisation & Promotion Platform (MPP)',\n",
       " 'Data Analyst 1',\n",
       " 'Ref Data Analyst',\n",
       " 'Revenue Ops Data Analyst',\n",
       " 'Job Openings For Data Analyst-Bangalore',\n",
       " 'Data Analyst (SQL, Excel & Python)_Max 15 days joiners',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - I/II',\n",
       " 'Senior Data Analyst']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in title_tag:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "print(len(job_title))    \n",
    "job_title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"ed4bf781-a027-40c2-88b1-c83fc889c8ee\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"3931b9ce-cf41-49de-a496-ab0a45ae90b7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"a77bb7f3-eb3d-4ee5-8548-ceaf7cfd3892\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"9f92e888-d9df-4035-a42e-e23ff873a158\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"8f67be9a-2963-4705-802f-4ae611ad00bc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"a1bcef66-67cf-4a53-a10d-b42d525c599f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"6a09ad73-f927-49c4-996a-83327648f03a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"49c807dd-711f-40d8-8d48-31935336655f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"5202737f-f6af-43af-a310-bd991aa2d977\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"605aebcc-cc82-44dc-a2d2-8194c48c2bdc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"7d694b6b-ed2b-470c-95df-5f0d8e581c49\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"6fbf48de-2c4a-4148-a5aa-19d4958f4fbd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"e0bfa9ed-9ece-48fe-974b-101e4c069fd6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"04b482c2-7e8e-4b1d-8668-76895d67d59b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"415d10e4-aaa8-4244-a287-8acb8eef9b34\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"f25778cb-a817-401a-a65f-7bc085276d72\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"ccb95217-324e-4779-84d9-2b16a26920dc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"15a62088-facd-4f50-9e77-f7e38df34934\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"258ab205-c646-40ce-bac0-f017f8c39fab\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"89b39b30-96e8-41ad-9245-e0dc7ee07ed1\")>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in location_tag:\n",
    "    loc=i.text\n",
    "    job_location.append(loc)\n",
    "    \n",
    "print(len(job_location))\n",
    "job_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"eaf42372-100e-46a3-a11c-b47dce55a6dc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"57014f95-8586-4ea9-949e-635c93c3601e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"77985a30-8087-45d7-90a4-82d18bb3490b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"4cc97a2a-52ce-4688-9cc7-1317050d95bf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"94e522f9-f553-4e96-b1b0-b23c85e406b1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"af505066-9be5-4290-b374-190a1660ff4f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"75d0cef1-b60f-45bc-a902-58fecba3cfd5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"7260e7d3-5a70-489d-b829-4fabea31a751\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"604975ec-9fe7-483e-9e69-2a2b6e5bc8cb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"9d33eeae-1756-4f7b-a56a-75e305a37d48\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"fb4e8fdc-f617-43f3-bce4-d50c024f1449\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"ce9db8e5-b6f9-4054-8fec-178ce71b099d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"a290a914-ef9f-449a-bc5c-a73818bb563b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"7c4cf781-ff25-4101-83af-5980fa928fb6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"a3700880-1282-4249-a669-761c9b23b1e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"09399807-a067-4472-aa17-25c9b0e50ac0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"83438a99-caa1-4ca1-871c-c1e546b430ef\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"27947433-0421-478a-9b4d-94f4320024c1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"78be525c-3e0d-4e7a-a3ed-ed0de1d4cc91\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"0749b583-612b-449a-a788-ba406d7c2e40\")>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_tag=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "name_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NetApp',\n",
       " 'Byjus - Transforming Education using Technology',\n",
       " 'Allegis Services India Pvt. Ltd.',\n",
       " 'Integrated Digital Systems',\n",
       " 'INDIAVIDUAL LEARNING LIMITED',\n",
       " 'Flipkart',\n",
       " 'Applied Materials',\n",
       " 'Huawei Technologies',\n",
       " 'RANDSTAD INDIA PVT LTD',\n",
       " 'Scienaptic Systems',\n",
       " 'Gojek Tech',\n",
       " 'GO-JEK India',\n",
       " 'Optum Global Solutions (India) Private Limited',\n",
       " 'NTT Data',\n",
       " 'Trifacta',\n",
       " 'QUIN BAY TECHNOLOGIES PRIVATE LIMITED',\n",
       " 'Quadrangle Search',\n",
       " 'Amazon Development Centre (India) Pvt. Ltd.',\n",
       " 'Philips India Limited',\n",
       " 'Flipkart Internet Private Limited']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in name_tag:\n",
    "    name=i.text.replace(\"\\n\",'')\n",
    "    company_name.append(name)\n",
    "    \n",
    "print(len(company_name))\n",
    "company_name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"8358bb60-792d-4519-8d98-01e727660620\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"5006ac54-666f-4042-9a02-44d0dc66718e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"cf5d498b-c539-4c14-b368-af632f3e918b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"60bfa5ed-f05b-4fd6-bc49-8b4403b39962\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"aec68440-e1ec-4d9d-9781-df6f9b3b4c11\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"97ac4e70-9266-4022-b12f-235503411f5c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"5f9c541a-1ca3-41ea-8069-9a7ece020231\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"061f4523-5069-4f8b-a605-c6f6fd00f814\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"ce591992-d2f8-45f4-88de-bcd7d82da551\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"72667a00-1e9b-4cc5-9f99-939691c52c03\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"68f67eb3-ab41-4701-af57-086e4a202264\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"a7d1f362-5ffe-42a2-aa6a-84acbcf5ac6c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"49ec321f-ae3e-40bf-8ccd-95e9c6dab1e2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"c152a5ad-8eab-45d1-973a-fba1fd15d3dc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"dc90d3f4-1a9a-4e9e-bb28-d25f4072dcea\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"9049c8e2-dbd4-4aa3-9743-f5d580f9d887\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"f5441051-0a34-4820-b02f-265f27cd44a4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"3008694c-7a09-4ce8-a7d6-99eda52b5caf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"1704a421-c381-4813-8ec4-84120961f6d8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"b537b4f1452213d2f52ef4578148c6e9\", element=\"984fc558-9593-49d6-b1ee-5fc5443bbd6b\")>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3-7 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-3 Yrs',\n",
       " '0-2 Yrs',\n",
       " '2-6 Yrs',\n",
       " '1-4 Yrs',\n",
       " '0-3 Yrs',\n",
       " '5-10 Yrs',\n",
       " '8-12 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-7 Yrs',\n",
       " '4-9 Yrs',\n",
       " '6-11 Yrs',\n",
       " '1-4 Yrs',\n",
       " '5-7 Yrs',\n",
       " '2-4 Yrs',\n",
       " '2-5 Yrs',\n",
       " '2-4 Yrs',\n",
       " '3-6 Yrs',\n",
       " '2-5 Yrs']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in exp_tag:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)\n",
    "    \n",
    "print (len(experience_required))\n",
    "experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe \n",
    "DataAnalyst_BLR=pd.DataFrame({})\n",
    "DataAnalyst_BLR[\"job_title\"]=job_title\n",
    "DataAnalyst_BLR[\"job_location\"]=job_location\n",
    "DataAnalyst_BLR[\"company_name\"]=company_name\n",
    "DataAnalyst_BLR[\"experience_required\"]=experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the  deatils byond 10 job data \n",
    "DataAnalyst_BLR.drop(range(10,20) , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reseting the indexes \n",
    "DataAnalyst_BLR.index=np.arange(1,len(DataAnalyst_BLR)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SQL Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - Marketing</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Byjus - Transforming Education using Technology</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Openings For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Integrated Digital Systems</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>INDIAVIDUAL LEARNING LIMITED</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst / Business Analyst (Demand Planning)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead Data Analyst / Data Engineer</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Huawei Technologies</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_title         job_location  \\\n",
       "1                                    SQL Data Analyst  Bangalore/Bengaluru   \n",
       "2                            Data Analyst - Marketing  Bangalore/Bengaluru   \n",
       "3                           Openings For Data Analyst  Bangalore/Bengaluru   \n",
       "4                              Associate Data Analyst  Bangalore/Bengaluru   \n",
       "5                               Business Data Analyst  Bangalore/Bengaluru   \n",
       "6   Data Analyst / Business Analyst (Demand Planning)  Bangalore/Bengaluru   \n",
       "7                                        Data Analyst  Bangalore/Bengaluru   \n",
       "8                   Lead Data Analyst / Data Engineer  Bangalore/Bengaluru   \n",
       "9                               Business Data Analyst  Bangalore/Bengaluru   \n",
       "10                                Senior Data Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "                                       company_name experience_required  \n",
       "1                                            NetApp             3-7 Yrs  \n",
       "2   Byjus - Transforming Education using Technology             0-2 Yrs  \n",
       "3                  Allegis Services India Pvt. Ltd.             0-3 Yrs  \n",
       "4                        Integrated Digital Systems             0-2 Yrs  \n",
       "5                      INDIAVIDUAL LEARNING LIMITED             2-6 Yrs  \n",
       "6                                          Flipkart             1-4 Yrs  \n",
       "7                                 Applied Materials             0-3 Yrs  \n",
       "8                               Huawei Technologies            5-10 Yrs  \n",
       "9                            RANDSTAD INDIA PVT LTD            8-12 Yrs  \n",
       "10                               Scienaptic Systems            5-10 Yrs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataAnalyst_BLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering job title in the search box \n",
    "search_jobs=driver2.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_jobs.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver2.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#THINGS TO SCRAP \n",
    "job-title, job-location, company_name, full job-description.---Data Scientist” Job position in “Bangalore” location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to use for data storage \n",
    "jobs_title=[]\n",
    "jobs_location=[]\n",
    "company_names=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying url of page to scrap \n",
    "DSurl=\"https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore\"\n",
    "driver2.get(DSurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"a2fe2418-7922-42b9-ab30-c9b1272bc11a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"9d822cd4-0526-4f18-a108-fd1a9db264a3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"dd95b8d6-c5a6-432c-8d3a-e5906dd181fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"61ad405f-b0f1-4a23-9085-2046c383e6e9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"be07ace5-c22c-456b-b3d9-a67367366bdb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"6eeb4388-dbb3-4ce4-a21a-14353d45f788\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"30290797-ee29-477e-a703-b11701672b2d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"78fff799-cb7d-4789-ac2e-6c686467902f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"d7a84aa2-4147-413a-97e2-d62e728fa77a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"2b61909c-f931-4081-94a7-91c9f1547788\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"f2ce662e-8cb8-42ca-a94a-5811ad4ee87f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"114dbe59-94be-4a69-9eca-ee77f576a321\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"fe9fca55-a30f-47d2-a23f-be95daacb539\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"31b83376-f50a-494e-a42b-e5583c999e1d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"1ccc992a-84b2-4461-ae1a-ad95f4e5d300\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"3657367b-a259-4372-bf29-fd5e9f8bd7c5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"5b3f3c1a-99b7-4c51-ba07-a3106a07ceb4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"7bc13c12-5cb6-4896-8601-cf4eef90c77b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"2d1a2eb8-245e-4eef-b174-195da0db6394\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"59ef649b-f62f-4c21-85b1-19f415ce345d\")>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tags=driver2.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sr. Data Scientist / Data Scientist For Bangalore & Kolkata Locations',\n",
       " 'Senior Data Scientist - Python/Machine Learning Algorithms',\n",
       " 'Lead Data Scientist',\n",
       " 'SDE2 Data Scientist',\n",
       " 'SDE1 Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Vice President Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist / AI / ML Engineer',\n",
       " 'Senior/Lead Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist, NLP',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist/Senior Data Scientist - IT Services Firm',\n",
       " 'Senior associate (Data Scientist)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    jobs_title.append(title)\n",
    "    \n",
    "print(len(jobs_title))    \n",
    "jobs_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"be91ce0e-ec7e-49fd-806a-f327590cf834\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"ac9610fb-09dc-405b-aa2d-9e548bd0f2a1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"dbcb81de-a91d-49e5-a90d-fcf0aa60de08\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"7facb54b-64d6-4b2f-9100-10aefd2a3922\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"4c93c221-257c-4e7f-bec3-ce4a9c30a020\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"a04bc234-5524-4573-ba1f-5ecf3ee75fdb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"de81cea1-ba37-4afb-85da-e83edac98534\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"52c933f8-6d97-4b07-b54c-372462a93d06\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"1e60daa5-42c5-4ab4-a083-5060d96d9084\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"c9049da3-6485-4c55-8510-c426398e6511\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"8fe8f6e2-0d57-41f3-bea6-aef18621216d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"5b6c4f82-9deb-4d58-927c-2b0503a9aa3d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"e63f191f-105b-40a3-b3f8-8333e9d159dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"83dd09db-bb8f-41b0-9896-c4d27ef90feb\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"1f7c7f87-45d1-44ab-baa4-f986dbde5982\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"6b852b9a-6fcb-42e5-b283-6abbbd60981c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"60453101-cb1f-453e-bd00-220a695b9620\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"405f4501-e868-43f7-ba79-d4dd9650cfb8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"ff9802b8-294b-4f88-8520-8662e24a7b90\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"ec1a13c1-7646-46ad-bea4-4ed91c99dabb\")>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_tags=driver2.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Kolkata, Bangalore/Bengaluru',\n",
       " 'Mumbai, Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Pune, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(Sadashiva Nagar)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in location_tags:\n",
    "    loc=i.text\n",
    "    jobs_location.append(loc)\n",
    "    \n",
    "print(len(jobs_location))\n",
    "jobs_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"b929ef9f-e0dd-4853-aa7e-c9f0dfa87eed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"58dcc960-475f-4a37-9a05-012cc1394db1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"1a640577-6a0f-4311-a52a-a2072f6a857f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"231ebe5d-5538-41ef-833e-7739911c74e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"aca1f00a-4a67-4eab-a4f5-7b40ea8af8f4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"5af986bd-57fe-46e5-a707-916d0fad7298\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"a31a177b-6b66-4964-8313-140dca1b5269\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"cf5bf99e-981d-4e70-914a-1a5e3ef6b364\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"ae839afa-e69e-41e8-a2bf-2f370feb9214\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"d54d0d79-a5e0-42c6-b632-94d4a144a459\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"acaf1452-887d-4e48-baa6-f4c615ad7df0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"c2806bd5-5517-48dd-bf70-1c13f2fd8f12\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"c52dead2-8d90-4c38-8dae-6e97d27211e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"8aa34e3f-dccc-4e9c-ac1f-2bf674697b7b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"a89db8d4-3f69-445c-8572-56527a940997\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"1e3b97ba-3c75-42d3-b0d7-b0b703c5c0db\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"fb68e883-fd18-4229-9f9c-f028fce7e33d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"075f0445-bfdd-45ce-a060-63f4c38bee9a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"d18fa577-e45a-4d9b-8cbb-7ae033650356\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"259f9be74b0e2e101d1e2f2233df37e5\", element=\"c9d69dcb-eda3-460e-b41c-1c7c1e99410b\")>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_tags=driver2.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "name_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mPokket',\n",
       " 'Altimax Business Solutions',\n",
       " 'Huawei Technologies',\n",
       " 'Multi Recruit',\n",
       " 'Multi Recruit',\n",
       " 'epiFi Technologies',\n",
       " 'Nutanix India Technologies Private Limited',\n",
       " 'ExecBoardinAsia',\n",
       " 'Capco Technologies Pvt Ltd',\n",
       " 'EXL Services.com ( I ) Pvt. Ltd.',\n",
       " 'Hitachi Ltd.',\n",
       " 'Scienaptic Systems',\n",
       " 'Executive Selection India',\n",
       " 'GO-JEK India',\n",
       " 'Convergence Infotech Ltd',\n",
       " 'Thomson Reuters',\n",
       " 'bd',\n",
       " 'Visa Inc.',\n",
       " 'Pylon Management Consulting Pvt Ltd',\n",
       " 'CHANGE LEADERS CONSULTING']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in name_tags:\n",
    "    name=i.text\n",
    "    company_names.append(name)\n",
    "    \n",
    "print(len(company_names))\n",
    "company_names\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.naukri.com/job-listings-sr-data-scientist-data-scientist-for-bangalore-kolkata-locations-mpokket-kolkata-bangalore-bengaluru-3-to-8-years-141021001893?src=jobsearchDesk&sid=16344106775532701&xp=1&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-python-machine-learning-algorithms-altimax-business-solutions-mumbai-hyderabad-secunderabad-pune-bangalore-bengaluru-4-to-9-years-020921908794?src=jobsearchDesk&sid=16344106775532701&xp=2&px=1',\n",
       " 'https://www.naukri.com/job-listings-lead-data-scientist-huawei-technologies-india-pvt-ltd-bangalore-bengaluru-4-to-9-years-121021907623?src=jobsearchDesk&sid=16344106775532701&xp=3&px=1',\n",
       " 'https://www.naukri.com/job-listings-sde2-data-scientist-multi-recruit-bangalore-bengaluru-2-to-7-years-141021501578?src=jobsearchDesk&sid=16344106775532701&xp=4&px=1',\n",
       " 'https://www.naukri.com/job-listings-sde1-data-scientist-multi-recruit-bangalore-bengaluru-8-to-13-years-141021501577?src=jobsearchDesk&sid=16344106775532701&xp=5&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-epifi-technologies-bangalore-bengaluru-3-to-5-years-141021501473?src=jobsearchDesk&sid=16344106775532701&xp=6&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-nutanix-india-technologies-private-limited-pune-bangalore-bengaluru-4-to-9-years-141021500782?src=jobsearchDesk&sid=16344106775532701&xp=7&px=1',\n",
       " 'https://www.naukri.com/job-listings-vice-president-data-scientist-execboardinasia-bangalore-bengaluru-11-to-15-years-141021500866?src=jobsearchDesk&sid=16344106775532701&xp=8&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-capco-technologies-pvt-ltd-bangalore-bengaluru-4-to-9-years-141021500034?src=jobsearchDesk&sid=16344106775532701&xp=9&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-exl-services-com-i-pvt-ltd-gurgaon-gurugram-bangalore-bengaluru-3-to-5-years-141021005203?src=jobsearchDesk&sid=16344106775532701&xp=10&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-ai-ml-engineer-hitachi-ltd-bangalore-bengaluru-5-to-10-years-111021500424?src=jobsearchDesk&sid=16344106775532701&xp=11&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-lead-data-scientist-scienaptic-systems-bangalore-bengaluru-10-to-12-years-041021500239?src=jobsearchDesk&sid=16344106775532701&xp=12&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-executive-selection-india-bangalore-bengaluru-5-to-10-years-141021900225?src=jobsearchDesk&sid=16344106775532701&xp=13&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-go-jek-india-bangalore-bengaluru-5-to-10-years-111021502002?src=jobsearchDesk&sid=16344106775532701&xp=14&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-convergence-infotech-ltd-bangalore-bengaluru-8-to-12-years-111021004221?src=jobsearchDesk&sid=16344106775532701&xp=15&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-nlp-thomson-reuters-international-services-pvt-ltd-bangalore-bengaluru-8-to-10-years-111021001745?src=jobsearchDesk&sid=16344106775532701&xp=16&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-bd-bangalore-bengaluru-2-to-5-years-091021500390?src=jobsearchDesk&sid=16344106775532701&xp=17&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-data-scientist-visa-inc-bangalore-bengaluru-4-to-9-years-011021501318?src=jobsearchDesk&sid=16344106775532701&xp=18&px=1',\n",
       " 'https://www.naukri.com/job-listings-data-scientist-senior-data-scientist-it-services-firm-pylon-management-consulting-pvt-ltd-hyderabad-secunderabad-pune-gurgaon-gurugram-bangalore-bengaluru-5-to-6-years-131021906976?src=jobsearchDesk&sid=16344106775532701&xp=19&px=1',\n",
       " 'https://www.naukri.com/job-listings-senior-associate-data-scientist-change-leaders-consulting-bangalore-bengaluru-1-to-5-years-141021603097?src=jobsearchDesk&sid=16344106775532701&xp=20&px=1']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_url=[]\n",
    "url_tag=driver2.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in url_tag:\n",
    "    ur=i.get_attribute('href')\n",
    "    job_url.append(ur)\n",
    "\n",
    "print(len(job_url))\n",
    "job_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_desc=[]\n",
    "\n",
    "\n",
    "for i in job_url:\n",
    "    driver2.get(i)\n",
    "    desc_tags=driver2.find_elements_by_xpath(\"//*[@class='dang-inner-html' or  @class='clearboth description' ]\")\n",
    "    for j in desc_tags:\n",
    "        dec=j.text.replace(\"\\n\",'')\n",
    "        full_desc.append(dec)\n",
    "\n",
    "#for i in range(10):\n",
    "    #full_desc.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"About The Job :- You will architect, code and deploy ML models (from scratch) to predict credit risk.- You will design, run, and analyze A/B and multivariate tests to test hypotheses aimed at optimizing user experience and portfolio risk.- You will perform data exploration and build statistical models on user behavior to discover opportunities for decreasing user defaults. And you must truly be excited about this part.- You'll use behavioral and social data to gain insights into how humans make financial choices- You will spend a lot of time in building out predictive features from super sparse data sources.- You'll continually acquire new data sources to develop a rich dataset that characterizes risk.- You will code, drink, breathe and live python, sklearn and pandas. It's good to have experience in these but not a necessity - as long as you're super comfortable in a language of your choice.About You :- You've strong computer science fundamentals- You've strong understanding of ML algorithms- Ideally, you have 2+ years of experience in using ML in the industry environment- You know how to run tests and understand their results from a statistical perspective- You love freedom and hate being micromanaged. You own products end to end- You have a strong desire to learn and use the latest machine learning algorithms- It will be great if you have one of the following to share - a kaggle or a github profile- Degree in statistics/quant/engineering from Tier-1 institutes.Skills:- Data Science, Python, Perl, Django, Machine Learning (ML) and Data Analytics\",\n",
       " 'We are looking for a Lead data scientist who will help us discover the information hidden in vast amounts of Ad Campaign data, and help us to optimize the campaign to improve the advertiser ROI and improve the overall consumer experience. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems using Deep learning algorithms integrated with our products. Some the key area you will be working on spend recommendation, floor price prediction, CTR/CVR prediction, market funnel analysis and perdition of lead to conversion, etc.Responsibility:Analyze the data, develop insights and identify the opportunity to utilize the data to predict various Advertisement key indicators like CTR, CVR, Inventory and Develop prediction and optimization algorithms for campaign, look alike modeling, etc for Huawei Ads.Takeup key challenges in AI-driven Smart Ad Serving Platform and focus on research and developing leading AI algorithms and productionize for Huawei Ads.Takeup initiative in identifying the SOTA and finding key gaps in AI algorithms and develop a world leading AI algorithms for optimizing real-time Ad Serving engine. Identify and optimize the core modules such as Traffic Prediction, Optimization, Ad Targeting/Re-targeting, Ad Performance Optimization, Audience insights, Attribution, Bidding, re-ranking, and Diagnostics. Support hundreds of billions of ad requests per day, with efficiently cache technology.To build and enhance Ad platform features and Prediction capabilities in Huawei Ads PlatformOptimized Cost Per Mille; Optimized Cost Per Action; Optimized Cost Per Click and Cost per Click. OCPM, OCPA, OCPC.Requirements:- Strong hands-on experience in implementing and validating big data algorithms and models including Deep Learning models like Seq2Seq/ GRU/ RNN/LSTM , Knowledge Graph, Massive Graph algorithms, etc.- Programming experience with Python- Able to validate existing models including Deep Learning models with large scale dataset and able to make changes to the models to achieve better performance- AdServing domain Experience is an added advantage.',\n",
       " 'Use data to develop machine learning models that optimize decision making in Credit Risk, Fraud, Marketing, and OperationsImplement data pipelines, new features, and algorithms that are critical to our production modelsCreate scalable strategies to deploy and execute your modelsWrite well designed, testable, efficient codeIdentify valuable data sources and automate collection processes.Undertake pre-processing of structured and unstructured data.Analyze large amounts of information to discover trends and patterns.Requirements:2+ years of experience in applied data science or engineering with a focus on machine learningPython expertise with good knowledge of machine learning libraries, tools, techniques, and frameworks (e.g. pandas, sklearn, xgboost, lightgbm, logistic regression, random forest classifier, gradient boosting regressor etc)Strong quantitative and programming skills with a product-driven sensibility-',\n",
       " 'Use data to develop machine learning models that optimize decision making in Credit Risk, Fraud, Marketing, and OperationsImplement data pipelines, new features, and algorithms that are critical to our production modelsCreate scalable strategies to deploy and execute your modelsWrite well designed, testable, efficient codeIdentify valuable data sources and automate collection processes.Undertake pre-processing of structured and unstructured data.Analyze large amounts of information to discover trends and patterns.Requirements:1+ years of experience in applied data science or engineering with a focus on machine learningPython expertise with good knowledge of machine learning libraries, tools, techniques, and frameworks (e.g. pandas, sklearn, xgboost, lightgbm, logistic regression, random forest classifier, gradient boosting regressor etc)Strong quantitative and programming skills with a product-driven sensibility-',\n",
       " 'At epiFi you will :Research and build predictive models to help users make the best financial decisionsInfluence data-driven decisions through end-to-end ownership of experiments : from collecting and building hypothesesto establishing statistical significance on resultsCollaborate closely with other functions on modeling ideas and building analyticsYou should apply if :You have at least 3 to 5 years of industry experience in data mining, machine learning, statistical analysis, and modelingYou have a MS or PhD in Computer Science, Physics, Statistics, Applied Mathematics, or any quantitative disciplinesYou have have a keen interest in financial services and a passion for shipping high-quality consumer-facing productsYou are able to self-manage your priorities and deliverables while working in a fast-paced, startup environmentYou have a solid foundation in computer science and strong competencies in data structures, algorithms, and software design, expertise with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methodsYou are experienced in one or more of the following areas: Machine Learning (ML) models, ML infrastructure, Natural Language Processing or Deep LearningYou are proficient in one or more data-oriented programming languages / tools (e.g. Python, R, Pandas, Scikit-learn, Jupyter) and database languages (e.g. SQL)You have built and prototyped analysis pipelines iteratively to provide insights at scale, on tools such as Hive, Spark, AWS RedshiftYou have a spark that separates you from the crowd and ability to think out of the box and on your feetYou possess multi-dimensional skills that make you a valuable co-worker in a fast, changing and ambiguous environmentYou have the ability to learn other coding languages as needed real quickYou are comfortable in working with a team that deals with ambiguity every dayYou can articulate complicated technical concepts clearlyWed also love to see :Interesting hobby projects, open-source contributions, etcSharing of knowledge - via either formal mentoring, reviewing code, reviewing design documents, providing technical talks, teaching classes, or as a consultant on projects',\n",
       " 'Objectives of this RoleCollaborate with product design and engineering to develop an understanding of needsResearch and devise innovative statistical models for data analysisCommunicate findings to all stakeholdersEnable smarter business processes and implement analytics for meaningful insightsKeep current with technical skillsets and industry developmentsResponsibilitiesWork as the lead data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the Product Support Organization to strategize and execute the development of new data products and maintain existing onesExecute analytical experiments methodically to help solve various problems and make a true impact across various domains and industriesIdentify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variablesDevise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracyAnalyze data for trends and patterns, and Interpret data with a clear objective in mindImplement analytical models into production by collaborating with software developers and machine learning engineers.Communicate analytic solutions to stakeholders and implement improvements as neededSkills and QualificationsBachelor s degree in statistics, applied mathematics, or related discipline7+ years experience in data scienceProficiency with data mining, mathematics, and statistical analysisAdvanced predictive modeling experienceExperience with Excel, PowerPoint, Tableau, SQL, and proficient in one of the programming languages (i.e., Python/R/Scala/SAS)Preferred QualificationsMaster s degree in stats, applied math, or related disciplineExperience in Natural Language Processing (NLP) algorithms, recommendation engine will be a plus.',\n",
       " 'This role will be responsible for all aspects of software development, testing and ensuring compatibility with enterprise and solutions architecture by harnessing modern development technologies.The position is for a Vice President within the Asset and Wealth Management Technology within the newly formed AI/ML - Data Science Intelligent Decisions team. The team is part of the Client Services Ops and Technology team and are responsible for system utilized by Client Advisors and WM Operations. The team is envisioning to define solutions helping Ops to move from Spreadsheets and heritage system to more AI based solutions.The team is looking for a hands-on senior software manager to build a new team from scratch and lead a small team of 4-5 data scientists. This position will give you immense opportunity to work on some latest technologies. The role will also provide a rich functional experience and an excellent platform to expand your knowledge on the corporate action domain and bring exciting changes to the existing platform.Responsibilities IncludeAs a member of a diverse team, you will participate in the full engineering life cycle which includes designing, developing, optimizing, and deploying new software solutionsLead and continue to build out a team of Data Scientists in the regionWithin the client services space you would be required to deep dive into the customer s problem and identifying use cases that could represent an opportunity for transformational or disruptive innovation using the Machine learning models.You will partner with the firm wide Data Science, Machine Learning, and Platform Engineering teams to develop and deploy production quality code and help establish a governance for the sustained performance and outcome of developed AI/Model modelsLead recruiting and onboarding team members directly manage 5 - 10 team membersFrom India you would be responsible for all the model s lifecycle management, governance, risk assessment and periodic recertification along with the central risk teams and competent authorities.You would be required to not only do PoC s but also build out project charters and own end to end responsibilities for deploying the models into production.',\n",
       " 'We are/have:Experts in banking and payments, capital markets and wealth and asset managementDeep knowledge in financial services offering, including e.g. Finance, Risk and Compliance, Financial Crime, Core Banking etc.Committed to growing our business and hiring the best talent to help us get there Focused on maintaining our nimble, agile and entrepreneurial cultureCapco is looking for hardworking, innovative and creative people to join our team. Must possess strong relationship management skills and be able to manage requirements and testing across Ops and IT teams both cross-division and globally. Role is focused on projects to support the development of regulatory/industry driven changes.Role DescriptionThis role provides regulatory data analytics using data from different geography. The primary responsibilities would be:Experience in data scienceExperience in marketing analytics is a plusExcellent analytical skills and commercial acumenGood understanding of the control requirements surrounding data handlingStrong self-starter with strong change delivery skills who enjoys the challenge of delivering change within tight deadlinesStrong verbal and written communication skillsAbility to manage multiple prioritiesKnowledge of and experience using data models and data dictionaries in a Banking and Financial Markets contextPreferable knowledge and experience in Data Quality GovernanceCan write SQL queries, Scala knowledge preferable and navigate data bases especially Hive, CMD, Putty, Note++Experience of using and flattening XMLExperience of big data programmes preferableEnthusiastic and energetic problem solver to join an ambitious teamBusiness analysis skills, defining and understanding requirementsAttention to detailGood knowledge of SDLC and formal Agile processes, a bias towards TDD and a willingness to test products as part of the delivery cycleAbility to communicate effectively in a multi-programme environment across a range of stakeholders',\n",
       " 'Roles and ResponsibilitiesBe involved in the approach to the problem, structure and delivery of the solution.Contribute to how analytical approach is structured for specification of analysis.Solve business problems by applying advanced Machine Learning algorithms and complex statistical models on large volumes of data.Contribute insights from conclusions of analysis that integrate with initial hypothesis and business objective. Independently address complex problems.Extremely comfortable working with data, including managing large number of data sources, analyzing data quality, and pro-actively working with clients data.Become an expert in clients information assets.Build, scale and deploy holistic data science products after successful prototyping.Reformulate highly technical information into concise, understandable terms for presentations.Doing research on advanced and better ways of solving the problems and inculcating new learnings to the team.Desired Candidate Profile2-4 years experience with solid analytical skills and an entrepreneurial, hands-on approach.Strong hands on programming skills in Python, SQL. Experience with large data sets and analytical tools.Excellent understanding of traditional machine learning techniques and algorithms, such as K-means, KNN, SVM, Random Forests etc. Experience using ML, DL frameworks (such as Scikit-learn, XGBoost, TensorFlow, Keras etc.)Strong experience in presenting analytical insights using powerpoint/excel. Case interview is expected.Candidates who have published white papers, research papers in the field of computer science and data science are desirable',\n",
       " 'Duties and ResponsibilitiesImplement the application solving customer s issue by applying AI/ML technologiesApply ML and DL models for various industry problems.Setting-up collaboration environment and framework for AI related research and development projects.Design and develop different architectural models for scalable data storage, processing, and large-scale analytics.Work with cross-functional teams to understand technical needs.Set-up big data environment that helps establish rapid POCs and prototype developments on both on-premises and cloud-based platforms.Monitor and optimize performance of the big data ecosystem.Ensure data accessibility to researchers via different programming languages.Keep up to date with state of the art in the industry.QualificationsMinimumBachelor s degree in Computer Science with substantial industry experience of 5 years or more of Data Engineering/ETL/Administration experience.Hands-on experience in Statistical data analysis and Machine learningPossess significant knowledge of Big Data technologies and tools.Good coding skills in at least one scripting language (Shell, Python, R, etc.)Experience with various Hadoop distribution like Hortonworks and Cloudera.Knowledge of cluster monitoring tools like Ambari, Ganglia, or Nagios.Delivered Big Data solutions in the cloud with AWS or Azure or Google Cloud.Experience in Java programming, Scala programming.Experience with RDBMS (MySQL, PostgreSQL, etc.)Experience with NoSQL database administration development like MongoDB.Experience with Hadoop eco-system (MapReduce, Streaming, Pig, HIVE, Spark).Experience using DevOps toolbox such as Jenkins, Chef, Puppet.Proven ability to create and manage big data pipeline using Kafka, Flume SparkKnowledge of BI tools such as Tableau, Pentaho, etc.Experience building large-scale distributed applications and services.Experience with agile development methodologies. -Knowledge of industry standards and trends.Good communication, logical thinking, and presentation skills.Additional qualifications (preferred but not mandatory)Master s degree in Computer Science or equivalent with at least 5 years industry experience of data engineering/ETL/Administration.Experience applying Deep learning.Substantial industry experience developing prototypes and demonstrating PoCs',\n",
       " 'We are looking for an energetic and experienced person as Sr/Lead Data Scientist. The chosen candidate will be responsible for interacting with clients and developing all aspects of data mining, predictive analytic, solution development to name a few.RequirementsLead and take part in end-to-end ML (Machine Learning) projects deployments that require feasibility analysis, design, development, validation, and application of state-of-the art data science solutions.Need to deliver solutions to production through the software development lifecycle.You will have to push the state of the art application in terms of data mining, visualization, predictive modelling, statistics, trend analysis, and other data analysis techniques to solve complex business problems including recommender systems, Customer sentiment modelling, customer life-cycle modelling, Spare parts inventory optimization, spare parts pricing, warranty, After market channel effectiveness.Write production ready code and deploy real time ML models; expose ML outputs through APIs.Hypothesis Testing and Design of experiments to analyze and monitor resultsPartner with Data/ML engineers and vendor partners for input data pipes development and ML models automation.Skills5 10 years of Applied Machine learning experience in the fields of Machine Learning, Recommender Systems, Statistical Modelling, Predictive Modelling.Note: We are looking for candidates who are presently serving their notice or who can join us within 15-20 days.',\n",
       " '1. Minimum 4 years of Data Scientist experience.2. Working with large datasets (several Gigs), using Azure ML Studio and proprietary data science modeling platform3. Designing and building scalable data analytics solutions at an enterprise level and high-performance analytical models using Python, ML libraries, Jupyter notebooks4. Building algorithms, statistical models and analytical solutions creatively and efficiently5. Design & architect powerful visualizations of data model performance and results.6. Responsible for setting up the data analytics model design & scripting the algorithm using python7. Solving data-intensive problems using industry standard data analytics frameworks and tools.8. Use multivariate techniques & predictive modeling – cluster analysis, discriminant analysis, CHAID, logistic & multiple regression analysis9. Large scale data extraction/mining, data cleansing, diagnostics, preparation for Modeling10. Intensive use of significance testing, sampling, descriptive statistics & multivariate statistics',\n",
       " 'What You Will DoWork with Data Scientists, Machine Learning Engineers, and Business Users to build, deploy, and scale Data Science solutions on match-making, supply, pricing problems in Gojek that touch the company s baselineUse your experience in Data Science, Machine Learning, Software Engineering, distributed systems to develop these systems, and work with the platform team to take the systems to productionWork with Business teams to continuously refine and improve the systems to cater to ever-changing Gojek needsDesign and develop world class Data Science solutions to enhance the current stack of Marketplace algorithms for supply, demand, pricingWhat You Will NeedAt least 6 years of experience as a Data Scientist or Machine Learning Engineer, with experience in Python, Golang/Java, and UnixA Bachelors Degree in Computer Science, Statistics, Operations Research, or a relevant quantitative fieldSolid knowledge of Data Science and Machine Learning fundamentals, with proven experience formulating Data Science solutions to business problemsProven ability to recognize business needs and to communicate with multiple stakeholders within the Product Management, Business and Operations teamsExperience in taking Data Science models to productionPrior academic or industry work experience with forecasting methods like auto-regressive models, Markov models, and Kernel-based methodsPrior experience with simulations for modeling the stochastic nature of marketplace supply and demand, and knowledge of the transportation and mobility space',\n",
       " 'Roles and ResponsibilitiesPhD in Statistics, Math or Computer Science is preferred. Must have at least a Master degree with 10+ years of experience.Excellent statistical analysis skills to identify patterns in data. This includes having a keen sense of pattern detection and anomaly detection.Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.Must be able to implement algorithms and statistical concepts to build predictive models.In-depth experience with common data science tools such as TensorFlow, PyTorch or equivalent.Proficient in programming with python, SQL and No-SQL databases; and data science libraries such as nltk, numpy, scipy and many othersGreat communication skills both written and verbal. Must be able to effectively communicate with global English speaking teams.Expertise in collaborating with multi-disciplinary teams of business analysts, data scientists, subject matter experts, and developersDesired Candidate ProfilePerks and Benefits',\n",
       " \"Senior Data Scientist, NLPAre you excited about working at the forefront of applied research in an industry setting? Thomson Reuters Labs in Bangalore is seeking experienced data scientists with a passion for solving problems using state-of-the-art Machine Learning and Natural Language Processing.What does Thomson Reuters Labs do? We experiment, we build, we deliver. We support the organization and our customers through applied research and the development of new products and technologies. TR Labs innovates collaboratively across our core segments in Legal, Tax & Accounting, Government, and Reuters News.  We undertake a diverse portfolio of projects today while investing in long-term research for the future.As a data scientist in Labs, you will be part of a global interdisciplinary team of experts. We hire specialists across a variety of AI research areas, as well as Engineering and Design, to drive the company's digital transformation. TR Labs is known for consistently delivering Artificial Intelligence projects that advance the state of the art in support of high growth products and serve Thomson Reuters customers in new and exciting ways.About the roleIn this opportunity as a Senior Data Scientist, you will:Experiment and Develop: You will drive the entire model development lifecycle, building, testing, and delivering high-quality solutions. You will apply best practices for conducting reproducible research and well-managed software delivery.Collaborate: Working on a collaborative cross-functional team, you will share information, value diverse ideas, and partner effectively with colleagues across the globe. You will elevate and mentor teammates.Deliver: With a strong sense of urgency and the desire to work in a fast-paced, dynamic environment, you will translate complex business problems into projects with a clearly defined scope. Our problems are complex; our solutions are right-sized. You will be accountable for timely, well-managed deliverables.Innovate:  You will be empowered to try new approaches and learn new technologies. You will implement innovative ideas to solve real-world challenges.Inspire: You will be a proactive communicator who is excited to share your work. You will be articulate and compelling in describing ideas to both technical and non-technical audiences. You will help lead the way in the adoption of AI across the enterprise.About youBasic qualificationsPh.D. in a relevant discipline or Masters plus a comparable level of experienceAt least five years experience building ML/NLP systemsSolid software engineering skills for prototypingExperience as a technical leader, coordinating and guiding the work of othersPreferred qualifications8+ years of academic or industry experience building ML or NLP systems with the demonstrated ability to translate cutting edge research into working applicationsDemonstrated ability to translate customer needs into well-structured research/project plansProficiency in Python, Java, or Scala and experience delivering minimum viable products in a large enterprise environmentOutstanding communication, organization, and data-driven decision makingPublications at workshops or conferences such as ACL, EMNLP, KDD, ICML, NeurIPS, or similarWhat's in it for youAt Thomson Reuters, our people are our greatest assets. In addition to rewarding and challenging work with exceptional colleagues, we offer the following benefits for your personal and professional growth:Learning & Development: On-the-job coaching & learning, tuition reimbursement, exposure to leading-edge technologyOur Scientists and Engineers get to play with big data sets to discover new products, capabilities, and insights for our customers. Thomson Reuters is most well-known for the globally respected Reuters News agency, but our company is also the leading source of information for legal, corporate, and tax professionals. We have over 60,000 TBs worth of legal, regulatory, news, and tax data. Benefits: Flexible work arrangements, comprehensive health coverage effective day one, savings and investment plansPerks: Social events & activities, employee discount programsSocial Impact: Paid time off for volunteering virtually or in your community\",\n",
       " '  Understand business problems and develop end-to-end data science use casesCollaborate across the function to understand data and to find ways to visualize and communicate your work to both technical and non-technical audiences.Evolve best data operational practices and maintain all compliance requirementsMonitor data science models in productionActively network on a regular basis with SME to better understand the business/technical mechanics that generated the dataPromote collaboration and knowledge exchange with other data science teams within and outside the organizationDevelop processes and tools to monitor and analyze model performance and data accuracyOne or more scientific programming languages such as R, Python, or Julia,One or more database query languages such as SQL, or HiveQL,One or more general-purpose scripting languages such as Bash, PowerShell, or Perlrovide the total years of experience and the relevant experience required in the relevant field for this positionSkillsTechnical / Functional SkillsBehavioural SkillsSoft SkillsLeadership Skills',\n",
       " 'What a Manager, DS Center of Excellence does at Visa:The person will be part of the Visa Consulting and Analytics (VCA) team will report into Data science leadSpecific responsibilities will include:Building & helping our partners to build data science capabilities & analytical solutions to solve their business problemsWorking knowledge in retail banking & credit card domain to guide the teams on the solution architectureDrive innovation through using data science techniquesAct as data science advocate within our partners, advising and coaching analytical teams and sharing best practices and case studies.Continually look at the environment to challenge our assumptions around new sources of data, potential analytics partners, tools, talent and infrastructure.Explore leading methodologies and best practices to other teams and importing successful methodologies from other international marketsWhy this is important to VisaVisas Consulting and Data Science team is a key part of the Global Solutions organization; a high-performing team of data scientists, data analysts and statisticians helping major organizations adapt and evolve to meet the changes taking place in technology, finance, and commerce; with cutting-edge, creative and advanced analytic solutions. The purpose of this team is to help Visas clients to grow their business & solve their problems by providing consulting services through visa data.QualificationsWhat you will need:Bachelors degree in Statistics, Mathematics, Computer Science, related fieldExperience in Card or Retail banking analytical domain is necessaryExperience in managing multiple stakeholders at client site5+ years of experience in data science, analytics, and statistical modeling or relevant areaExperience in SQL and statistical programming languagesWork experience scaling data engineering such as APIs or data self-service solutionsWhat will also help:Knowledge of Payment industryExperience in working closely with data science communityOutstanding problem-solving skills, with demonstrated ability to think creatively and strategicallySelf-motivated, results oriented individual with the ability to handle numerous projectsTechnology-driven mindset, digitally curiousUp-to-date with digital and technology literature, trends.Able to challenge the status quo diplomatically and bring teams along with strategy.',\n",
       " 'Roles and ResponsibilitiesExperience: 2 years – 4 years Education requirement: B. Tech/BE or MSc or MBA or MTech in Stats, Economics, Mathematics, Finance or any other quantitative disciplinePrimary Role: Substantial hands-on experience with data handling. Capable of managing large volumes of data, extract, clean and comprehend Able to analyze data independently and draw out salient insights. Able to define workflow for oneself and Associates on a daily or periodic basis, contingent on the requirements of the project Able to contribute meaningfully to brainstorming discussions around nuances of the project Comfortable with statistical procedures, such as basic distributions, regressions, logistic models Experience with advanced statistics and Machine Learning algorithms is a plus Developing comprehensible analytical solutions to solve business problems using domain knowledge or statistical procedures depending on the requirements of the project Comfortable in representing the proceedings and/or findings in a power-point Comfortable in mentoring junior resources, and creating an environment of learning in the team Helping the company with Business Development initiatives such as sales collaterals, PoCs, Case Studies Develop and define an area of expertise and take relevant trainings on the same for the organization Contribute to org level activities, such as taking interviewsCompetences: Relevant analytics experience in Retail, e-commerce, Telecom, or any other domain Technical Capabilities: o SQL o MSFT PowerPoint o Excel o Statistical Packages – R and/or Python – Mandate; PySpark, Scala is a plus o Statistical Modelling and/or Machine Learning, Deep Learning o Big Data Environments such as Hadoop, Hive, etc. o Any credentials from IITs and NITs are good to have on the resume']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    company_names.pop()\n",
    "    jobs_location.pop()\n",
    "    jobs_title.pop()\n",
    "    \n",
    "for i in range(8):\n",
    "    full_desc.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>company_names</th>\n",
       "      <th>job_location</th>\n",
       "      <th>Full description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Data Scientist / Data Scientist For Bangal...</td>\n",
       "      <td>mPokket</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru</td>\n",
       "      <td>About The Job :- You will architect, code and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist - Python/Machine Learnin...</td>\n",
       "      <td>Altimax Business Solutions</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Bangalor...</td>\n",
       "      <td>We are looking for a Lead data scientist who w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Huawei Technologies</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Use data to develop machine learning models th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDE2 Data Scientist</td>\n",
       "      <td>Multi Recruit</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Use data to develop machine learning models th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SDE1 Data Scientist</td>\n",
       "      <td>Multi Recruit</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>At epiFi you will :Research and build predicti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>epiFi Technologies</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Objectives of this RoleCollaborate with produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Nutanix India Technologies Private Limited</td>\n",
       "      <td>Pune, Bangalore/Bengaluru</td>\n",
       "      <td>This role will be responsible for all aspects ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vice President Data Scientist</td>\n",
       "      <td>ExecBoardinAsia</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>We are/have:Experts in banking and payments, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Capco Technologies Pvt Ltd</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Roles and ResponsibilitiesBe involved in the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Duties and ResponsibilitiesImplement the appli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title   \\\n",
       "1   Sr. Data Scientist / Data Scientist For Bangal...   \n",
       "2   Senior Data Scientist - Python/Machine Learnin...   \n",
       "3                                 Lead Data Scientist   \n",
       "4                                 SDE2 Data Scientist   \n",
       "5                                 SDE1 Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7                                      Data Scientist   \n",
       "8                       Vice President Data Scientist   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                                company_names   \\\n",
       "1                                      mPokket   \n",
       "2                   Altimax Business Solutions   \n",
       "3                          Huawei Technologies   \n",
       "4                                Multi Recruit   \n",
       "5                                Multi Recruit   \n",
       "6                           epiFi Technologies   \n",
       "7   Nutanix India Technologies Private Limited   \n",
       "8                              ExecBoardinAsia   \n",
       "9                   Capco Technologies Pvt Ltd   \n",
       "10            EXL Services.com ( I ) Pvt. Ltd.   \n",
       "\n",
       "                                         job_location  \\\n",
       "1                        Kolkata, Bangalore/Bengaluru   \n",
       "2   Mumbai, Hyderabad/Secunderabad, Pune, Bangalor...   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4                                 Bangalore/Bengaluru   \n",
       "5                                 Bangalore/Bengaluru   \n",
       "6                                 Bangalore/Bengaluru   \n",
       "7                           Pune, Bangalore/Bengaluru   \n",
       "8                                 Bangalore/Bengaluru   \n",
       "9                                 Bangalore/Bengaluru   \n",
       "10              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                                    Full description   \n",
       "1   About The Job :- You will architect, code and ...  \n",
       "2   We are looking for a Lead data scientist who w...  \n",
       "3   Use data to develop machine learning models th...  \n",
       "4   Use data to develop machine learning models th...  \n",
       "5   At epiFi you will :Research and build predicti...  \n",
       "6   Objectives of this RoleCollaborate with produc...  \n",
       "7   This role will be responsible for all aspects ...  \n",
       "8   We are/have:Experts in banking and payments, c...  \n",
       "9   Roles and ResponsibilitiesBe involved in the a...  \n",
       "10  Duties and ResponsibilitiesImplement the appli...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scientist=pd.DataFrame({})\n",
    "data_scientist[\"Job title \"]=jobs_title\n",
    "data_scientist[\"company_names \"]=company_names\n",
    "data_scientist[\"job_location\"]=jobs_location\n",
    "data_scientist[\"Full description \"]=full_desc\n",
    "data_scientist.index=np.arange(1,len(data_scientist)+1)\n",
    "data_scientist10=data_scientist[:10]\n",
    "data_scientist10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .        \n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually .   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering job title in the search box \n",
    "search_jobs=driver3.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_jobs.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver3.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#THINGS TO SCRAP \n",
    "job datascience \n",
    "job-title, job-location, company_name, experience_required-,\n",
    "salary filter “3-6” lakhs,” \n",
    "Job position in loaction filter - “Delhi/NCR” location . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the location \n",
    "location_box=driver3.find_element_by_xpath(\"//*[@class='ellipsis fleft' and @title='Delhi / NCR']\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering the  salary \n",
    "salary_box=driver3.find_element_by_xpath(\"//*[@class='ellipsis fleft' and @title='3-6 Lakhs']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sr. Data Scientist / Data Scientist For Bangalore & Kolkata Locations',\n",
       " 'Lead Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist/Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Job Opportunity || Data Scientist || HCL Technologies',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist I',\n",
       " 'Hiring Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Requirement For Data Scientist',\n",
       " 'Urgent Requirement: Data Scientist',\n",
       " 'Requirement For Data Scientist',\n",
       " 'Data Scientist I/II/III']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title3=[]\n",
    "title_tag3=driver3.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag3\n",
    "\n",
    "for i in title_tag3:\n",
    "    title=i.text\n",
    "    job_title3.append(title)\n",
    "    \n",
    "print(len(job_title3))    \n",
    "job_title3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Kolkata, Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad(Madhapur)',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru',\n",
       " 'Tiruchirapalli/Trichy',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Delhi / NCR',\n",
       " 'Vadodara',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru(5th block Koramangala)',\n",
       " 'Pune',\n",
       " 'Noida',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad',\n",
       " 'Chennai',\n",
       " 'Bhayandar',\n",
       " 'Chennai',\n",
       " 'Gurgaon/Gurugram']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Location3=[] # initiated  empty list \n",
    "\n",
    "#finding all the tags \n",
    "location_tag3=driver3.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "location_tag3\n",
    "\n",
    "for i in location_tag3:\n",
    "    loc=i.text\n",
    "    Location3.append(loc)\n",
    "    \n",
    "print(len(Location3))    \n",
    "Location3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mPokket',\n",
       " 'Huawei Technologies',\n",
       " 'EXL Services.com ( I ) Pvt. Ltd.',\n",
       " 'Sadup softech Pvt Ltd',\n",
       " 'Hexagon Geosystems Services India P.Ltd.',\n",
       " 'CourseBricks',\n",
       " 'Successr HR Tech PVT LTD',\n",
       " 'HCL Technologies',\n",
       " 'PIRAMAL ENTERPRISES LTD',\n",
       " 'Kwalee India Pvt Ltd.',\n",
       " 'Perform Group',\n",
       " 'IHX private limited',\n",
       " 'Citylink Technology Solutions Pvt. Ltd.',\n",
       " 'Newgen Software Technologies Ltd.',\n",
       " 'Applied Materials',\n",
       " '3rdflix Visual Effects Pvt. Ltd. - Practically',\n",
       " 'Access Healthcare Services Pvt Ltd',\n",
       " 'Epicenter Technologies Pvt. Ltd',\n",
       " 'Access Healthcare Services Pvt Ltd',\n",
       " 'OLX India Pvt Ltd']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_name=[] # initiated  empty list \n",
    "\n",
    "#finding all the tags \n",
    "name_tag3=driver3.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "name_tag3\n",
    "\n",
    "for i in name_tag3:\n",
    "    name=i.text\n",
    "    c_name.append(name)\n",
    "\n",
    "print(len(c_name))    \n",
    "c_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3-8 Yrs',\n",
       " '4-9 Yrs',\n",
       " '3-5 Yrs',\n",
       " '6-11 Yrs',\n",
       " '1-6 Yrs',\n",
       " '4-8 Yrs',\n",
       " '4-7 Yrs',\n",
       " '1-6 Yrs',\n",
       " '2-7 Yrs',\n",
       " '1-3 Yrs',\n",
       " '4-6 Yrs',\n",
       " '0-2 Yrs',\n",
       " '2-5 Yrs',\n",
       " '2-4 Yrs',\n",
       " '2-4 Yrs',\n",
       " '4-8 Yrs',\n",
       " '2-4 Yrs',\n",
       " '4-8 Yrs',\n",
       " '3-6 Yrs']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Expp=[] # initiated  empty list \n",
    "\n",
    "#finding all the tags \n",
    "exp_tag3=driver3.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "exp_tag3\n",
    "\n",
    "for i in exp_tag3:\n",
    "    ex=i.text\n",
    "    Expp.append(ex)\n",
    "    \n",
    "print(len(Expp))    \n",
    "Expp    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(c_name))\n",
    "print(len(Location3))\n",
    "print(len(job_title3))\n",
    "print(len(Expp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    c_name.pop()\n",
    "    Location3.pop()\n",
    "    job_title3.pop()\n",
    "\n",
    "for i in range(9):\n",
    "    Expp.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_filter=pd.DataFrame({})    \n",
    "DS_filter[\"Company name \"]=c_name\n",
    "DS_filter[\"Company Location \"]=Location3\n",
    "DS_filter[\"Job title \"]=job_title3\n",
    "DS_filter[\"Experience reuired \"]=Expp \n",
    "DS_filter.index=np.arange(1,len(DS_filter)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company name</th>\n",
       "      <th>Company Location</th>\n",
       "      <th>Job title</th>\n",
       "      <th>Experience reuired</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mPokket</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru</td>\n",
       "      <td>Sr. Data Scientist / Data Scientist For Bangal...</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huawei Technologies</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sadup softech Pvt Ltd</td>\n",
       "      <td>Hyderabad/Secunderabad(Madhapur)</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hexagon Geosystems Services India P.Ltd.</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CourseBricks</td>\n",
       "      <td>Tiruchirapalli/Trichy</td>\n",
       "      <td>Data Scientist/Senior Data Scientist</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Successr HR Tech PVT LTD</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>Job Opportunity || Data Scientist || HCL Techn...</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PIRAMAL ENTERPRISES LTD</td>\n",
       "      <td>Vadodara</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kwalee India Pvt Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company name   \\\n",
       "1                                    mPokket   \n",
       "2                        Huawei Technologies   \n",
       "3           EXL Services.com ( I ) Pvt. Ltd.   \n",
       "4                      Sadup softech Pvt Ltd   \n",
       "5   Hexagon Geosystems Services India P.Ltd.   \n",
       "6                               CourseBricks   \n",
       "7                   Successr HR Tech PVT LTD   \n",
       "8                           HCL Technologies   \n",
       "9                    PIRAMAL ENTERPRISES LTD   \n",
       "10                     Kwalee India Pvt Ltd.   \n",
       "\n",
       "                        Company Location   \\\n",
       "1            Kolkata, Bangalore/Bengaluru   \n",
       "2                     Bangalore/Bengaluru   \n",
       "3   Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "4        Hyderabad/Secunderabad(Madhapur)   \n",
       "5   Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "6                   Tiruchirapalli/Trichy   \n",
       "7                     Bangalore/Bengaluru   \n",
       "8                             Delhi / NCR   \n",
       "9                                Vadodara   \n",
       "10                    Bangalore/Bengaluru   \n",
       "\n",
       "                                           Job title  Experience reuired   \n",
       "1   Sr. Data Scientist / Data Scientist For Bangal...             3-8 Yrs  \n",
       "2                                 Lead Data Scientist             4-9 Yrs  \n",
       "3                                      Data Scientist             3-5 Yrs  \n",
       "4                                      Data Scientist            6-11 Yrs  \n",
       "5                                      Data Scientist             1-6 Yrs  \n",
       "6                Data Scientist/Senior Data Scientist             4-8 Yrs  \n",
       "7                                      Data Scientist             4-7 Yrs  \n",
       "8   Job Opportunity || Data Scientist || HCL Techn...             1-6 Yrs  \n",
       "9                                      Data Scientist             2-7 Yrs  \n",
       "10                                     Data Scientist             1-3 Yrs  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.get(\"https://www.glassdoor.co.in/member/home/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering job title in the search box \n",
    "time.sleep(3)\n",
    "search_job=driver4.find_element_by_id(\"sc.keyword\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "search_loca=driver4.find_element_by_id(\"sc.location\")\n",
    "search_loca.send_keys(\"Noida\")\n",
    "\n",
    "search=driver4.find_element_by_xpath(\"//span[@class='css-8zxfjs']\")\n",
    "search.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pixel Vision',\n",
       " 'HDFC Bank',\n",
       " 'Innovacer',\n",
       " 'UnitedHealth Group',\n",
       " 'Crowe',\n",
       " 'Salasar New Age Technologies',\n",
       " 'AlgoScale Technologies Private Limited',\n",
       " 'AIIMS, Delhi',\n",
       " 'CODEC Networks Pvt ltd',\n",
       " 'Liberin Technologies Private Limited',\n",
       " 'Techlive',\n",
       " 'Optum - India',\n",
       " 'RannLab Technologies',\n",
       " 'dunnhumby',\n",
       " 'Salasar New Age Technologies',\n",
       " 'NEC Opportunities',\n",
       " 'Biz2Credit Inc',\n",
       " 'TransOrg Analytics',\n",
       " 'Iraitech Innovations & Tehcnologies Pvt.Ltd',\n",
       " 'Kline & Company',\n",
       " 'R Systems',\n",
       " 'UnitedHealth Group',\n",
       " 'Newgen Software',\n",
       " 'Ericsson',\n",
       " 'UnitedHealth Group',\n",
       " 'Emerging India Group',\n",
       " 'TransOrg Analytics',\n",
       " 'UnitedHealth Group',\n",
       " 'IBM',\n",
       " 'SearchUrCollege']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company=[]\n",
    "name_tag=driver4.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']\")\n",
    "for i in name_tag:\n",
    "    com=i.text\n",
    "    company.append(com)\n",
    "print (len(company))\n",
    "company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GIS Data Scientist',\n",
       " 'Data Scientist-CAI',\n",
       " 'Data Scientist - Sales Analytics',\n",
       " 'Associate Manager Data Scientist - Noida, UP',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist Intern',\n",
       " 'Data Scientist',\n",
       " 'Data Entry Operator, Research Asst, Scientist B',\n",
       " 'Data Scientist Intern',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist – Gurgaon/Noida',\n",
       " 'Python/AI/Big Data Developer | Research Profile',\n",
       " 'Applied Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Machine Learning Intern',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Python ( 5-7 Years )',\n",
       " 'Data Scientist - Gurgaon/Noida',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Noida, UP',\n",
       " 'Assistant Manager/Deputy Manager/Manager - Sales - Data Analytics Training Solutions',\n",
       " 'Data Scientist Ops',\n",
       " 'Lead Data Scientist - IJP - Noida, UP',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_title=[]\n",
    "job_tag=driver4.find_elements_by_xpath(\"//a[@class='jobLink job-search-key-1rd3saf eigr9kq1']\")\n",
    "for i in job_tag:\n",
    "    job=i.text\n",
    "    Job_title.append(job)\n",
    "print (len(Job_title))\n",
    "Job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Noida',\n",
       " 'Gurgaon',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Greater Noida',\n",
       " 'Gurgaon',\n",
       " 'Noida',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Gurgaon',\n",
       " 'New Delhi',\n",
       " 'New Delhi',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Gurgaon',\n",
       " 'Noida',\n",
       " 'Noida',\n",
       " 'Noida']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Job_loc=[]\n",
    "loc_tag=driver4.find_elements_by_xpath(\"//span[@class='css-1buaf54 pr-xxsm job-search-key-iii9i8 e1rrn5ka4']\")\n",
    "for i in loc_tag:\n",
    "    loc=i.text\n",
    "    Job_loc.append(loc)\n",
    "print (len(Job_title))\n",
    "Job_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['5d',\n",
       " '5d',\n",
       " '5d',\n",
       " '8d',\n",
       " '15d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '4d',\n",
       " '19d',\n",
       " '30d+',\n",
       " '30d+',\n",
       " '24d',\n",
       " '1d',\n",
       " '3d',\n",
       " '30d+',\n",
       " '17d',\n",
       " '30d+',\n",
       " '10d',\n",
       " '9d',\n",
       " '3d',\n",
       " '15d',\n",
       " '24d',\n",
       " '30d+',\n",
       " '15d',\n",
       " '11d',\n",
       " '30d+',\n",
       " '10d',\n",
       " '30d',\n",
       " '30d+',\n",
       " '30d+']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posted=[]\n",
    "post_tag=driver4.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-17n8uzw']\")\n",
    "\n",
    "for i in post_tag:\n",
    "    try:\n",
    "        po=i.text\n",
    "        posted.append(po)\n",
    "    except:\n",
    "        posted.append(\"_____\")\n",
    "        \n",
    "print (len(posted))\n",
    "posted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_template=pd.DataFrame({})\n",
    "job_template[\"company name \"]=company\n",
    "job_template[\"job name\"]=Job_title\n",
    "job_template[\"job location \"]=Job_loc\n",
    "job_template[\"posed time\"]=posted\n",
    "job_template.index=np.arange(1,len(job_template)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company name</th>\n",
       "      <th>job name</th>\n",
       "      <th>job location</th>\n",
       "      <th>posed time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pixel Vision</td>\n",
       "      <td>GIS Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDFC Bank</td>\n",
       "      <td>Data Scientist-CAI</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Innovacer</td>\n",
       "      <td>Data Scientist - Sales Analytics</td>\n",
       "      <td>Noida</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Associate Manager Data Scientist - Noida, UP</td>\n",
       "      <td>Noida</td>\n",
       "      <td>8d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AlgoScale Technologies Private Limited</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIIMS, Delhi</td>\n",
       "      <td>Data Entry Operator, Research Asst, Scientist B</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CODEC Networks Pvt ltd</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>19d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Liberin Technologies Private Limited</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Optum - India</td>\n",
       "      <td>Data Scientist – Gurgaon/Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>24d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RannLab Technologies</td>\n",
       "      <td>Python/AI/Big Data Developer | Research Profile</td>\n",
       "      <td>Greater Noida</td>\n",
       "      <td>1d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dunnhumby</td>\n",
       "      <td>Applied Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEC Opportunities</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>17d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TransOrg Analytics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Iraitech Innovations &amp; Tehcnologies Pvt.Ltd</td>\n",
       "      <td>Machine Learning Intern</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>9d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kline &amp; Company</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>R Systems</td>\n",
       "      <td>Data Scientist - Python ( 5-7 Years )</td>\n",
       "      <td>Noida</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Data Scientist - Gurgaon/Noida</td>\n",
       "      <td>Noida</td>\n",
       "      <td>24d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Newgen Software</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Data Scientist - Noida, UP</td>\n",
       "      <td>Noida</td>\n",
       "      <td>11d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Emerging India Group</td>\n",
       "      <td>Assistant Manager/Deputy Manager/Manager - Sal...</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TransOrg Analytics</td>\n",
       "      <td>Data Scientist Ops</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>10d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Lead Data Scientist - IJP - Noida, UP</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>IBM</td>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SearchUrCollege</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>30d+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  company name   \\\n",
       "1                                  Pixel Vision   \n",
       "2                                     HDFC Bank   \n",
       "3                                     Innovacer   \n",
       "4                            UnitedHealth Group   \n",
       "5                                         Crowe   \n",
       "6                  Salasar New Age Technologies   \n",
       "7        AlgoScale Technologies Private Limited   \n",
       "8                                  AIIMS, Delhi   \n",
       "9                        CODEC Networks Pvt ltd   \n",
       "10         Liberin Technologies Private Limited   \n",
       "11                                     Techlive   \n",
       "12                                Optum - India   \n",
       "13                         RannLab Technologies   \n",
       "14                                    dunnhumby   \n",
       "15                 Salasar New Age Technologies   \n",
       "16                            NEC Opportunities   \n",
       "17                               Biz2Credit Inc   \n",
       "18                           TransOrg Analytics   \n",
       "19  Iraitech Innovations & Tehcnologies Pvt.Ltd   \n",
       "20                              Kline & Company   \n",
       "21                                    R Systems   \n",
       "22                           UnitedHealth Group   \n",
       "23                              Newgen Software   \n",
       "24                                     Ericsson   \n",
       "25                           UnitedHealth Group   \n",
       "26                         Emerging India Group   \n",
       "27                           TransOrg Analytics   \n",
       "28                           UnitedHealth Group   \n",
       "29                                          IBM   \n",
       "30                              SearchUrCollege   \n",
       "\n",
       "                                             job name  job location   \\\n",
       "1                                  GIS Data Scientist          Noida   \n",
       "2                                  Data Scientist-CAI        Gurgaon   \n",
       "3                    Data Scientist - Sales Analytics          Noida   \n",
       "4        Associate Manager Data Scientist - Noida, UP          Noida   \n",
       "5                                      Data Scientist          Noida   \n",
       "6                               Data Scientist Intern          Noida   \n",
       "7                                      Data Scientist          Noida   \n",
       "8     Data Entry Operator, Research Asst, Scientist B      New Delhi   \n",
       "9                               Data Scientist Intern      New Delhi   \n",
       "10                           Associate Data Scientist          Noida   \n",
       "11                                     Data Scientist          Noida   \n",
       "12                     Data Scientist – Gurgaon/Noida          Noida   \n",
       "13    Python/AI/Big Data Developer | Research Profile  Greater Noida   \n",
       "14                             Applied Data Scientist        Gurgaon   \n",
       "15                                     Data Scientist          Noida   \n",
       "16                                     Data Scientist      New Delhi   \n",
       "17                                     Data Scientist          Noida   \n",
       "18                                     Data Scientist        Gurgaon   \n",
       "19                            Machine Learning Intern      New Delhi   \n",
       "20                                     Data Scientist      New Delhi   \n",
       "21              Data Scientist - Python ( 5-7 Years )          Noida   \n",
       "22                     Data Scientist - Gurgaon/Noida          Noida   \n",
       "23                                     Data Scientist          Noida   \n",
       "24                                     Data Scientist          Noida   \n",
       "25                         Data Scientist - Noida, UP          Noida   \n",
       "26  Assistant Manager/Deputy Manager/Manager - Sal...          Noida   \n",
       "27                                 Data Scientist Ops        Gurgaon   \n",
       "28              Lead Data Scientist - IJP - Noida, UP          Noida   \n",
       "29            Data Scientist: Artificial Intelligence          Noida   \n",
       "30                                     Data Scientist          Noida   \n",
       "\n",
       "   posed time  \n",
       "1          5d  \n",
       "2          5d  \n",
       "3          5d  \n",
       "4          8d  \n",
       "5         15d  \n",
       "6        30d+  \n",
       "7        30d+  \n",
       "8          4d  \n",
       "9         19d  \n",
       "10       30d+  \n",
       "11       30d+  \n",
       "12        24d  \n",
       "13         1d  \n",
       "14         3d  \n",
       "15       30d+  \n",
       "16        17d  \n",
       "17       30d+  \n",
       "18        10d  \n",
       "19         9d  \n",
       "20         3d  \n",
       "21        15d  \n",
       "22        24d  \n",
       "23       30d+  \n",
       "24        15d  \n",
       "25        11d  \n",
       "26       30d+  \n",
       "27        10d  \n",
       "28        30d  \n",
       "29       30d+  \n",
       "30       30d+  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver4.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page\n",
    "You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6.Store the data in a dataframe.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.get(\"https://www.glassdoor.co.in/Salaries/index.htm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_jobs=driver5.find_element_by_id(\"KeywordSearch\")\n",
    "search_jobs.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver5.find_element_by_id(\"HeroSearchButton\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Mu Sigma',\n",
       " 'IBM',\n",
       " 'Tata Consultancy Services',\n",
       " 'Impact Analytics',\n",
       " 'Accenture',\n",
       " 'Infosys',\n",
       " 'Capgemini',\n",
       " 'Cognizant Technology Solutions',\n",
       " 'Anheuser-Busch InBev',\n",
       " 'Fractal',\n",
       " 'Embibe',\n",
       " 'Amazon',\n",
       " 'Google',\n",
       " 'Ericsson-Worldwide',\n",
       " 'Flipkart',\n",
       " 'HP Inc.',\n",
       " 'Wipro',\n",
       " 'Genpact',\n",
       " 'Fresher',\n",
       " 'MiQ']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_name=[]\n",
    "\n",
    "name_tag5=driver5.find_elements_by_xpath(\"//a[@class='css-f3vw95 e1aj7ssy3']\")\n",
    "\n",
    "for i in name_tag5:\n",
    "    name=i.text\n",
    "    com_name.append(name)\n",
    "    \n",
    "print(len(com_name))\n",
    "com_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['₹6,51,353/yr',\n",
       " '₹11,78,399/yr',\n",
       " '₹8,77,705/yr',\n",
       " '₹6,71,046/yr',\n",
       " '₹9,67,613/yr',\n",
       " '₹9,09,257/yr',\n",
       " '₹9,47,042/yr',\n",
       " '₹7,53,281/yr',\n",
       " '₹16,51,026/yr',\n",
       " '₹14,30,228/yr',\n",
       " '₹14,10,795/yr',\n",
       " '₹14,11,911/yr',\n",
       " '₹15,64,775/yr',\n",
       " '₹12,26,988/yr',\n",
       " '₹25,79,728/yr',\n",
       " '₹15,26,678/yr',\n",
       " '₹7,79,837/yr',\n",
       " '₹10,09,162/yr',\n",
       " '₹5,50,000/yr',\n",
       " '₹16,79,815/yr']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_sal=[]\n",
    "\n",
    "avg_tag5=driver5.find_elements_by_xpath(\"//div[@class='col-12 col-lg-4 px-lg-0 d-flex align-items-baseline']\")\n",
    "\n",
    "for i in avg_tag5:\n",
    "    avg=i.text.replace(\"\\n \",'')\n",
    "    avg_sal.append(avg)\n",
    "    \n",
    "print(len(avg_sal))\n",
    "avg_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['₹3L',\n",
       " '₹2L',\n",
       " '₹2L',\n",
       " '₹5L',\n",
       " '₹4L',\n",
       " '₹4L',\n",
       " '₹5L',\n",
       " '₹3L',\n",
       " '₹12L',\n",
       " '₹10L',\n",
       " '₹9L',\n",
       " '₹3L',\n",
       " '₹3L',\n",
       " '₹3L',\n",
       " '₹18L',\n",
       " '₹4L',\n",
       " '₹2L',\n",
       " '₹5L',\n",
       " '₹2L',\n",
       " '₹14L']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_sal=[]\n",
    "\n",
    "min_tag5=driver5.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']/p[1]\")\n",
    "\n",
    "for i in min_tag5:\n",
    "    mn=i.text.replace(\"\\n\",'')\n",
    "    min_sal.append(mn)\n",
    "    \n",
    "print(len(min_sal))\n",
    "min_sal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['₹49L',\n",
       " '₹43L',\n",
       " '₹26L',\n",
       " '₹9L',\n",
       " '₹31L',\n",
       " '₹33L',\n",
       " '₹16L',\n",
       " '₹18L',\n",
       " '₹20L',\n",
       " '₹21L',\n",
       " '₹19L',\n",
       " '₹45L',\n",
       " '₹73L',\n",
       " '₹36L',\n",
       " '₹44L',\n",
       " '₹50L',\n",
       " '₹28L',\n",
       " '₹14L',\n",
       " '₹15L',\n",
       " '₹20L']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sal=[]\n",
    "\n",
    "max_tag5=driver5.find_elements_by_xpath(\"//div[@class='d-flex mt-xxsm css-79elbk epuxyqn0']/p[2]\")\n",
    "\n",
    "for i in max_tag5:\n",
    "    mx=i.text.replace(\"\\n \",'')\n",
    "    max_sal.append(mx)\n",
    "    \n",
    "print(len(max_sal))\n",
    "max_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['3.3',\n",
       " '3.9',\n",
       " '3.9',\n",
       " '3.9',\n",
       " '4.1',\n",
       " '3.3',\n",
       " '3.8',\n",
       " '3.8',\n",
       " '3.7',\n",
       " '4',\n",
       " '4.4',\n",
       " '3.7',\n",
       " '4.5',\n",
       " '4',\n",
       " '4.1',\n",
       " '4.2',\n",
       " '3.4',\n",
       " '3.8',\n",
       " '4.2',\n",
       " '3.9']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "\n",
    "rating_tag5=driver5.find_elements_by_xpath(\"//span[@class='m-0 css-kyx745']\")\n",
    "\n",
    "for i in rating_tag5:\n",
    "    rt=i.text.replace(\"\\n \",'')\n",
    "    rating.append(rt)\n",
    "    \n",
    "print(len(rating))\n",
    "rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company name</th>\n",
       "      <th>Minimum salary</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Maximum salary</th>\n",
       "      <th>company rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mu Sigma</td>\n",
       "      <td>₹49L</td>\n",
       "      <td>₹6,51,353/yr</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹43L</td>\n",
       "      <td>₹11,78,399/yr</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹26L</td>\n",
       "      <td>₹8,77,705/yr</td>\n",
       "      <td>₹2L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Impact Analytics</td>\n",
       "      <td>₹9L</td>\n",
       "      <td>₹6,71,046/yr</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹31L</td>\n",
       "      <td>₹9,67,613/yr</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>₹33L</td>\n",
       "      <td>₹9,09,257/yr</td>\n",
       "      <td>₹4L</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>₹16L</td>\n",
       "      <td>₹9,47,042/yr</td>\n",
       "      <td>₹5L</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cognizant Technology Solutions</td>\n",
       "      <td>₹18L</td>\n",
       "      <td>₹7,53,281/yr</td>\n",
       "      <td>₹3L</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Anheuser-Busch InBev</td>\n",
       "      <td>₹20L</td>\n",
       "      <td>₹16,51,026/yr</td>\n",
       "      <td>₹12L</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fractal</td>\n",
       "      <td>₹21L</td>\n",
       "      <td>₹14,30,228/yr</td>\n",
       "      <td>₹10L</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company name  Minimum salary Average salary  \\\n",
       "1                         Mu Sigma           ₹49L   ₹6,51,353/yr   \n",
       "2                              IBM           ₹43L  ₹11,78,399/yr   \n",
       "3        Tata Consultancy Services           ₹26L   ₹8,77,705/yr   \n",
       "4                 Impact Analytics            ₹9L   ₹6,71,046/yr   \n",
       "5                        Accenture           ₹31L   ₹9,67,613/yr   \n",
       "6                          Infosys           ₹33L   ₹9,09,257/yr   \n",
       "7                        Capgemini           ₹16L   ₹9,47,042/yr   \n",
       "8   Cognizant Technology Solutions           ₹18L   ₹7,53,281/yr   \n",
       "9             Anheuser-Busch InBev           ₹20L  ₹16,51,026/yr   \n",
       "10                         Fractal           ₹21L  ₹14,30,228/yr   \n",
       "\n",
       "   Maximum salary company rating  \n",
       "1             ₹3L            3.3  \n",
       "2             ₹2L            3.9  \n",
       "3             ₹2L            3.9  \n",
       "4             ₹5L            3.9  \n",
       "5             ₹4L            4.1  \n",
       "6             ₹4L            3.3  \n",
       "7             ₹5L            3.8  \n",
       "8             ₹3L            3.8  \n",
       "9            ₹12L            3.7  \n",
       "10           ₹10L              4  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdoor=pd.DataFrame({})\n",
    "gdoor[\"company name \"]=com_name\n",
    "gdoor[\"Minimum salary\"]=max_sal\n",
    "gdoor[\"Average salary\"]=avg_sal\n",
    "gdoor[\"Maximum salary\"]=min_sal\n",
    "gdoor[\"company rating\"]=rating\n",
    "gdoor.index=np.arange(1,len(gdoor)+1)\n",
    "gdoor10=gdoor.iloc[ :10]\n",
    "gdoor10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses.\n",
    "Note that all of the above steps have to be done by coding only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_glass =driver6.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "search_glass.send_keys(\"sunglasses\"+\"\\n\")\n",
    "#   +\"\\n\" works as enter button hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference - Every page contains 40  glass data so  to scrap 100 glasses data , code has to repeat 3 times at min.\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "brand_name=[]\n",
    "\n",
    "brand_tag=driver6.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "\n",
    "for i in brand_tag:\n",
    "    br=i.text\n",
    "    brand_name.append(br)\n",
    "    \n",
    "print(len(brand_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "url=[]\n",
    "for i in driver6.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "    url.append(i.get_attribute(\"href\"))\n",
    "print(len(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "discount=[]\n",
    "price=[]\n",
    "for i in url:\n",
    "    driver6.get(i)\n",
    "    try:\n",
    "        discount_tag=driver6.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount.append(discount_tag.text)                 \n",
    "    except:\n",
    "        discount.append(\"--\")\n",
    "\n",
    "        \n",
    "print(len(discount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "price=[]\n",
    "for i in url:\n",
    "    driver6.get(i)\n",
    "    \n",
    "    try:\n",
    "        price_tag=driver6.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price.append(price_tag.text)                 \n",
    "    except:\n",
    "        price.append(\"--\")\n",
    "    \n",
    "        \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_glass =driver6.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "search_glass.send_keys(\"sunglasses\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button=driver6.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "brand_tag2=driver6.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tag2:\n",
    "    br=i.text\n",
    "    brand_name.append(br)\n",
    "    \n",
    "print(len(brand_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2=[]\n",
    "for i in driver6.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "    url2.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "for i in url2:\n",
    "    driver6.get(i)\n",
    "    try:\n",
    "        discount_tag2=driver6.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount.append(discount_tag2.text)                 \n",
    "    except:\n",
    "        discount.append(\"--\")\n",
    "\n",
    "        \n",
    "print(len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "for i in url2:\n",
    "    driver6.get(i)\n",
    "    \n",
    "    try:\n",
    "        price_tag2=driver6.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price.append(price_tag2.text)                 \n",
    "    except:\n",
    "        price.append(\"--\")\n",
    "    \n",
    "        \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_glass =driver6.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "search_glass.send_keys(\"sunglasses\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button2=driver6.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next_button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "brand_tag3=driver6.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in brand_tag3:\n",
    "    br=i.text\n",
    "    brand_name.append(br)\n",
    "    \n",
    "print(len(brand_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3=[]\n",
    "for i in driver6.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "    url3.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "for i in url3:\n",
    "    driver6.get(i)\n",
    "    try:\n",
    "        discount_tag3=driver6.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount.append(discount_tag3.text)                 \n",
    "    except:\n",
    "        discount.append(\"--\")\n",
    "\n",
    "        \n",
    "print(len(discount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "for i in url3:\n",
    "    driver6.get(i)\n",
    "    \n",
    "    try:\n",
    "        price_tag3=driver6.find_element_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "        price.append(price_tag3.text)                 \n",
    "    except:\n",
    "        price.append(\"--\")\n",
    "    \n",
    "        \n",
    "print(len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglasses=pd.DataFrame({})\n",
    "sunglasses[\"brand name \"]=brand_name\n",
    "sunglasses[\"price\"]=price\n",
    "sunglasses[\"discount %\"]=discount\n",
    "sunglasses.index=np.arange(1,len(sunglasses)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand name</th>\n",
       "      <th>price</th>\n",
       "      <th>discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹467</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹799</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>HIPPON</td>\n",
       "      <td>₹257</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹639</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹354</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>₹640</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand name  price discount %\n",
       "1    VINCENT CHASE  ₹999    50% off\n",
       "2    VINCENT CHASE  ₹999    50% off\n",
       "3           PIRASO  ₹200    87% off\n",
       "4         Fastrack  ₹467    48% off\n",
       "5           PIRASO  ₹200    87% off\n",
       "..             ...   ...        ...\n",
       "116  VINCENT CHASE  ₹799    68% off\n",
       "117         HIPPON  ₹257    78% off\n",
       "118  VINCENT CHASE  ₹639    68% off\n",
       "119      Elligator  ₹354    76% off\n",
       "120         AISLIN  ₹640    82% off\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglass=sunglasses.iloc[ :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand name</th>\n",
       "      <th>price</th>\n",
       "      <th>discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹999</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹467</td>\n",
       "      <td>48% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹200</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹426</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>₹1,009</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹548</td>\n",
       "      <td>39% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹943</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand name    price discount %\n",
       "1     VINCENT CHASE    ₹999    50% off\n",
       "2     VINCENT CHASE    ₹999    50% off\n",
       "3            PIRASO    ₹200    87% off\n",
       "4          Fastrack    ₹467    48% off\n",
       "5            PIRASO    ₹200    87% off\n",
       "..              ...     ...        ...\n",
       "96   ROZZETTA CRAFT    ₹426    80% off\n",
       "97             IDEE  ₹1,009    50% off\n",
       "98        ROYAL SON    ₹399    73% off\n",
       "99         Fastrack    ₹548    39% off\n",
       "100   VINCENT CHASE    ₹943    52% off\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver6.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When you will open the above link you will reach to the below shown webpage.\n",
    "scrap-\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "page=(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\")\n",
    "driver7.get(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on next button \n",
    "driver7.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "urls=[]\n",
    "url_tag=driver7.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8' or @class='ge-49M']\")\n",
    "for i in url_tag:\n",
    "    web=i.get_attribute(\"href\")\n",
    "    urls.append(web)\n",
    "print (len(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 100\n",
      "full_review 100\n"
     ]
    }
   ],
   "source": [
    "title=[]\n",
    "full_review=[]\n",
    "\n",
    "for i in  urls:\n",
    "    driver7.get(i)\n",
    "\n",
    "        \n",
    "    title_tag=driver7.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for k in title_tag:\n",
    "        titl=k.text\n",
    "        title.append(titl)\n",
    "    \n",
    "    review_tag=driver7.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for l in review_tag:\n",
    "        rev=l.text\n",
    "        full_review.append(rev)\n",
    "\n",
    "print(\"title\" ,len(title))\n",
    "print(\"full_review\" ,len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating 100\n"
     ]
    }
   ],
   "source": [
    "#ref 1\n",
    "ratings=[]\n",
    "for i in urls:\n",
    "    driver7.get(i)\n",
    "    \n",
    "    rating_tag=driver7.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq' or @class='_3LWZlK _1rdVr6 _1BLPMq']\")\n",
    "    for j in rating_tag:\n",
    "        try:\n",
    "            rt=j.text\n",
    "            ratings.append(rt)\n",
    "        except:\n",
    "            ratings.append(\"no rating\")   \n",
    "            \n",
    "print(\"rating\" ,len(ratings))\n",
    "\n",
    "            #reference code gives only 98 values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#length check \n",
    "print (len(ratings))\n",
    "print (len (title))\n",
    "print(len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>titles</th>\n",
       "      <th>full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>A wort full value for money decision it’s . Si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating               titles  \\\n",
       "1        5            Brilliant   \n",
       "2        5       Simply awesome   \n",
       "3        5     Perfect product!   \n",
       "4        5            Fabulous!   \n",
       "5        5  Best in the market!   \n",
       "..     ...                  ...   \n",
       "96       5    Terrific purchase   \n",
       "97       5              Awesome   \n",
       "98       3       Decent product   \n",
       "99       5              Awesome   \n",
       "100      5            Brilliant   \n",
       "\n",
       "                                           full review  \n",
       "1    The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "2    Really satisfied with the Product I received.....  \n",
       "3    Amazing phone with great cameras and better ba...  \n",
       "4    This is my first iOS phone. I am very happy wi...  \n",
       "5    Great iPhone very snappy experience as apple k...  \n",
       "..                                                 ...  \n",
       "96   I use a Note10+ and have been using both iOS a...  \n",
       "97   The phone is completely good\\nAs far as camera...  \n",
       "98   Everything u ll like it when u use this iPhone...  \n",
       "99   Can’t beat the software and hardware integrati...  \n",
       "100  A wort full value for money decision it’s . Si...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone=pd.DataFrame({})\n",
    "iphone[\"rating\"]=ratings\n",
    "iphone[\"titles\"]=title\n",
    "iphone[\"full review\"]=full_review\n",
    "iphone.index=np.arange(1, len(iphone)+1)\n",
    "iphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver7.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "\n",
    "Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver8.find_element_by_xpath(\"//input[@title='Search for products, brands and more']\")\n",
    "search.send_keys(\"sneakers\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "url8=[]\n",
    "for i in driver8.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "    url8.append(i.get_attribute(\"href\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button=driver8.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver8.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "    url8.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver8.find_elements_by_xpath(\"//a[@class='_2UzuFa']\"):\n",
    "    url8.append(i.get_attribute(\"href\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(url8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "\n",
    "for i in url8:\n",
    "    driver8.get(i)\n",
    "    \n",
    "    br_tag=driver8.find_elements_by_xpath(\"//span[@class='G6XhRU']\")\n",
    "    for i in br_tag:\n",
    "        br=i.text\n",
    "        brand.append(br) \n",
    "    \n",
    "    des_tag=driver8.find_elements_by_xpath(\"//span[@class='B_NuCI']\")\n",
    "    for i in des_tag:\n",
    "        ds=i.text\n",
    "        description.append(ds) \n",
    "    \n",
    "    price_tag=driver8.find_elements_by_xpath(\"//div[@class='_30jeq3 _16Jk6d']\")\n",
    "    for i in price_tag:\n",
    "        pr=i.text\n",
    "        price.append(pr)\n",
    "    \n",
    "    try:\n",
    "        dt=driver8.find_elements_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        for i in dt:\n",
    "            dis=i.text\n",
    "            discount.append(dis)\n",
    "    except:\n",
    "        discount.append(\"no discount\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount=[]\n",
    "\n",
    "for i in url8:\n",
    "    driver8.get(i)\n",
    "        \n",
    "    try:\n",
    "        dt=driver8.find_element_by_xpath(\"//div[@class='_3Ay6Sb _31Dcoz pZkvcx']\")\n",
    "        discount.append(dt.text)                 \n",
    "    except:\n",
    "        discount.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print (len(discount))\n",
    "print (len(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneak_120=pd.DataFrame({})\n",
    "sneak_120[\"brand\"]=brand\n",
    "sneak_120[\"prodcut descrition\"]=description\n",
    "sneak_120[\"price\"]=price\n",
    "sneak_120[\"discount %\"]=discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers=sneak_120.iloc[ :100]\n",
    "sneakers.index=np.arange(1,len(sneakers)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>prodcut descrition</th>\n",
       "      <th>price</th>\n",
       "      <th>discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers Sneakers For Men  (White)</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual for men (beige 06) Sneakers For Men  (B...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bluemaker</td>\n",
       "      <td>casual for men (blue 06) Sneakers For Men  (Blue)</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Speed Set of 5 Pairs Sneakers Outdoors Casuals...</td>\n",
       "      <td>₹679</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shoes Bank</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men...</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Red Rose</td>\n",
       "      <td>Sneakers For Men  (Blue)</td>\n",
       "      <td>₹449</td>\n",
       "      <td>10% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-162 Sneakers For Men  (Black)</td>\n",
       "      <td>₹711</td>\n",
       "      <td>25% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern &amp; Trendy Collection Combo Pack of 02 Sh...</td>\n",
       "      <td>₹447</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 5 Casual Shoes Sneakers For Men ...</td>\n",
       "      <td>₹715</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Paragon</td>\n",
       "      <td>Sneakers For Men  (Blue)</td>\n",
       "      <td>₹584</td>\n",
       "      <td>35% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          brand                                 prodcut descrition price  \\\n",
       "1    SCATCHITE                  Sneakers Sneakers For Men  (White)  ₹398   \n",
       "2    bluemaker   casual for men (beige 06) Sneakers For Men  (B...  ₹424   \n",
       "3    bluemaker   casual for men (blue 06) Sneakers For Men  (Blue)  ₹424   \n",
       "4       Chevit   Speed Set of 5 Pairs Sneakers Outdoors Casuals...  ₹679   \n",
       "5   Shoes Bank   White Sneaker For Men's/Boy's Sneakers For Men...  ₹348   \n",
       "..          ...                                                ...   ...   \n",
       "76    Red Rose                            Sneakers For Men  (Blue)  ₹449   \n",
       "77       SPARX                    SM-162 Sneakers For Men  (Black)  ₹711   \n",
       "78      BRUTON   Modern & Trendy Collection Combo Pack of 02 Sh...  ₹447   \n",
       "79       BIRDE   Combo Pack of 5 Casual Shoes Sneakers For Men ...  ₹715   \n",
       "80     Paragon                            Sneakers For Men  (Blue)  ₹584   \n",
       "\n",
       "   discount %  \n",
       "1     60% off  \n",
       "2     57% off  \n",
       "3     57% off  \n",
       "4     72% off  \n",
       "5     65% off  \n",
       "..        ...  \n",
       "76    10% off  \n",
       "77    25% off  \n",
       "78    82% off  \n",
       "79    71% off  \n",
       "80    35% off  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver8.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "-Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image\n",
    "-And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "-Please note that applying the filter and scraping the data , everything should be done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.get(\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A6897.0_13595.0_6897.0%20TO%2013595.0%2C6927.0_13615.0_6927.0%20TO%2013615.0\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Could not execute filtering by code , used filtered url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand_name 50\n",
      "short_dec 50\n",
      "price 50\n"
     ]
    }
   ],
   "source": [
    "brand_name=[]\n",
    "n_tag=driver9.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "for i in n_tag:\n",
    "    n=i.text\n",
    "    brand_name.append(n)\n",
    "\n",
    "print(\"brand_name\" , len(brand_name))\n",
    "\n",
    "\n",
    "short_dec=[]\n",
    "d_tag=driver9.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "for i in d_tag:\n",
    "    n=i.text\n",
    "    short_dec.append(n)\n",
    "\n",
    "print(\"short_dec\" , len(short_dec))\n",
    "\n",
    "price=[]\n",
    "p_tag=driver9.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "for i in p_tag:\n",
    "    n=i.text\n",
    "    price.append(n)\n",
    "\n",
    "print(\"price\" , len(price))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button=driver9.find_element_by_xpath(\"//a[@rel='next']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand_name 100\n",
      "short_dec 100\n",
      "price 100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_tag=driver9.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "for i in n_tag:\n",
    "    n=i.text\n",
    "    brand_name.append(n)\n",
    "\n",
    "print(\"brand_name\" , len(brand_name))\n",
    "\n",
    "\n",
    "\n",
    "d_tag=driver9.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "for i in d_tag:\n",
    "    n=i.text\n",
    "    short_dec.append(n)\n",
    "\n",
    "print(\"short_dec\" , len(short_dec))\n",
    "\n",
    "\n",
    "p_tag=driver9.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "for i in p_tag:\n",
    "    n=i.text\n",
    "    price.append(n)\n",
    "\n",
    "print(\"price\" , len(price))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_shoe=pd.DataFrame({})\n",
    "black_shoe[\"Brand name\"]=brand_name\n",
    "black_shoe[\"Description\"]=short_dec\n",
    "black_shoe[\"price\"]=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand name</th>\n",
       "      <th>Description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Leather Solid Loafers</td>\n",
       "      <td>Rs. 10499Rs. 14999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Jamming 2.0 Running Shoes</td>\n",
       "      <td>Rs. 10399Rs. 12999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Driving Shoes</td>\n",
       "      <td>Rs. 11199Rs. 15999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Deviate Nitro Running Shoe</td>\n",
       "      <td>Rs. 11999Rs. 14999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Unisex FerrariRS-Fast Sneakers</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>KLEAT</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Suede Pumps</td>\n",
       "      <td>Rs. 8900Rs. 8990(1% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Solid Leather Gladiators</td>\n",
       "      <td>Rs. 9890Rs. 9990(1% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand name                     Description  \\\n",
       "0                   ALDO           Leather Solid Loafers   \n",
       "1                   Puma   Men Jamming 2.0 Running Shoes   \n",
       "2                   ALDO               Men Driving Shoes   \n",
       "3                   Puma  Men Deviate Nitro Running Shoe   \n",
       "4        PUMA Motorsport  Unisex FerrariRS-Fast Sneakers   \n",
       "..                   ...                             ...   \n",
       "95                  Geox          Men Leather Flat Boots   \n",
       "96                  Geox             Women Leather Pumps   \n",
       "97                 KLEAT       Men Woven Design Sneakers   \n",
       "98  Heel & Buckle London               Women Suede Pumps   \n",
       "99  Heel & Buckle London  Women Solid Leather Gladiators   \n",
       "\n",
       "                          price  \n",
       "0   Rs. 10499Rs. 14999(30% OFF)  \n",
       "1   Rs. 10399Rs. 12999(20% OFF)  \n",
       "2   Rs. 11199Rs. 15999(30% OFF)  \n",
       "3   Rs. 11999Rs. 14999(20% OFF)  \n",
       "4     Rs. 7999Rs. 9999(20% OFF)  \n",
       "..                          ...  \n",
       "95                    Rs. 11999  \n",
       "96                     Rs. 9999  \n",
       "97                     Rs. 7999  \n",
       "98     Rs. 8900Rs. 8990(1% OFF)  \n",
       "99     Rs. 9890Rs. 9990(1% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "black_shoe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver9.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10.get(\"https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031%2Cp_n_feature_thirteen_browse-bin%3A12598163031%7C16757432031&dc&qid=1634392958&rnid=12598141031&ref=sr_nr_p_n_feature_thirteen_browse-bin_25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title 30\n",
      "title10 10\n",
      "rating 31\n",
      "rating10 10\n",
      "price 30\n",
      "price10 10\n"
     ]
    }
   ],
   "source": [
    "title=[]\n",
    "t_tag=driver10.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in t_tag:\n",
    "    t=i.text\n",
    "    title.append(t)\n",
    "print(\"title\",len(title))\n",
    "\n",
    "title10=[]\n",
    "for i in range(10):\n",
    "    title10.append(title[i])\n",
    "print(\"title10\",len(title10))    \n",
    "\n",
    "\n",
    "rating=[]\n",
    "r_tag=driver10.find_elements_by_xpath(\"//span[@class='a-icon-alt']\")\n",
    "for i in r_tag:\n",
    "    r=i.text\n",
    "    rating.append(r)\n",
    "print(\"rating\",len(rating))\n",
    "\n",
    "rating10=[]\n",
    "for i in range(10):\n",
    "    rating10.append(rating[i])\n",
    "print(\"rating10\",len(rating10))\n",
    "\n",
    "\n",
    "price=[]\n",
    "p_tag=driver10.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in p_tag:\n",
    "    p=i.text\n",
    "    price.append(p)\n",
    "print(\"price\",len(price))\n",
    "\n",
    "price10=[]\n",
    "for i in range(10):\n",
    "    price10.append(price[i])\n",
    "print(\"price10\",len(price10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fujitsu UH-X 11th Gen Intel i7 Core 13.3” (33.78cm) FHD IPS 400Nits Thin and Light Laptop (16GB/512GB SSD/Win10/Office/Iris Xe Graphics/Backlit Kb/ Fingerprint Reader/Black/878gms), 4ZR1D67596',\n",
       " 'Lenovo IdeaPad S540 11th Gen Intel Core i7 13.3\" QHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Intel Iris Xe Graphics/Iron Grey/1.28Kg), 82H1002CIN',\n",
       " 'Acer Nitro 5 11th Gen Intel Core i7-11800H 15.6\" (39.62cms) Full HD Gaming Laptop (16 GB/256GB SSD/1 TB HDD/Win 10/RTX 3050 Ti 4GB Graphics/144 Hz, Black, 2.4 kg/RGB Backlit Keyboard) AN515-57',\n",
       " 'Mi Notebook Horizon Edition 14 Intel Core i7-10510U 10th Gen Thin and Light Laptop(8GB/512GB SSD/Windows 10/Nvidia MX350 2GB Graphics/Grey/1.35Kg)(Without Webcam) XMA1904-AF',\n",
       " 'Life Digital Laptop 15.6-inch (39.62 cms) (Intel Core i7, 4GB RAM, 256GB SSD, Windows 10), ZED AIR CX7',\n",
       " 'HP Pavilion (2021) Intel 11th Gen Core i7 14 inches FHD Screen Thin & Light Laptop, 16 GB RAM, 1TB SSD, Iris Xe Graphics, Windows 10, MS Office, Backlit Keyboard, 1.41kg (14-dv0058TU), Silver',\n",
       " 'Lenovo IdeaPad S540 11th Gen Intel Core i7 13.3\" QHD IPS Thin & Light Laptop (16GB/512GB SSD/Windows 10/MS Office 2019/Intel Iris Xe Graphics/Iron Grey/1.28Kg), 82H1002CIN',\n",
       " 'Lenovo ThinkBook 15 Intel 11th Gen Core i7 15.6\" (39.62 cm) FHD IPS 300 nits Antiglare 100% sRGB Thin and Light Laptop (16GB/512GB SSD/Windows 10/MS Office/3 Yr Onsite Warranty/1.7 Kg), 20VEA0HHIH',\n",
       " '(Renewed) Lenovo Thinkpad Hybrid Laptop T450s (Slim) Intel Core i7 - 5600u Processor, 12 GB Ram, 1TB Harddisk & 256 GB ssd, Windows 10 Pro, 14.1 Inches Notebook Computer',\n",
       " 'HP Pavilion 13(2021) 11th Gen Intel Core i7 Laptop, 16GB RAM, 1TB SSD, 13.3-inch(33.8 cm) FHD Screen, Win 10, MS Office, Ceramic White, 1.24 Kg (13-bb0078TU)']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel i7 Core 13.3” (33....</td>\n",
       "      <td>89,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>77,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Nitro 5 11th Gen Intel Core i7-11800H 15....</td>\n",
       "      <td>85,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>53,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>24,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>84,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad S540 11th Gen Intel Core i7 13....</td>\n",
       "      <td>77,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>93,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Lenovo Thinkpad Hybrid Laptop T450s ...</td>\n",
       "      <td>39,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP Pavilion 13(2021) 11th Gen Intel Core i7 La...</td>\n",
       "      <td>91,990</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   price rating\n",
       "0  Fujitsu UH-X 11th Gen Intel i7 Core 13.3” (33....  89,990       \n",
       "1  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....  77,990       \n",
       "2  Acer Nitro 5 11th Gen Intel Core i7-11800H 15....  85,990       \n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...  53,990       \n",
       "4  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  24,990       \n",
       "5  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...  84,990       \n",
       "6  Lenovo IdeaPad S540 11th Gen Intel Core i7 13....  77,990       \n",
       "7  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  93,990       \n",
       "8  (Renewed) Lenovo Thinkpad Hybrid Laptop T450s ...  39,990       \n",
       "9  HP Pavilion 13(2021) 11th Gen Intel Core i7 La...  91,990       "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop=pd.DataFrame({})\n",
    "laptop[\"title\"]=title10\n",
    "laptop[\"price\"]=price10\n",
    "laptop[\"rating\"]=rating10\n",
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver10.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
